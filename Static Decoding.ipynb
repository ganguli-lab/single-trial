{
 "metadata": {
  "language": "Julia",
  "name": "",
  "signature": "sha256:394fce52e8e3a30df64a1c39f130af403361d58dc249fbc169914a993e21ee26"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using PyPlot, Interact\n",
      "\n",
      "addprocs(12);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Generative model\n",
      "\n",
      "Our model for high-dimensional static decoding of neural activities:\n",
      "$$\n",
      "y^T = w^T \\left(X + Z \\right) + \\epsilon^T\n",
      "$$\n",
      "\n",
      "We have\n",
      "  - $X$, the $N$-by-$P$ signal matrix that is sampled from a $K$-dimensional sphere of radius $r$, i.e. i.i.d. $\\mathcal{N}(0, \\frac{r^2}{K})$, then embedded into the $N$-dimensional,\n",
      "  - $Z$, the $N$-by-$P$ activities noise with $Z_{ij} \\sim \\mathcal{N}(0, \\frac{1}{N})$,\n",
      "  - $w$, a length-$N$ decoding unit-vector in the $K$-dimensional signal space,\n",
      "  - $\\epsilon$, $P$ scalar noises for the behavior output draw i.i.d. from $\\mathcal{N}(0, s^2)$,\n",
      "  - $y$, $P$ scalar behavior outputs\n",
      "\n",
      "The generative model's parameters are $(N, K, P, r, s)$\n",
      "  \n",
      "### Observation model\n",
      "We model the observations of neural activities as\n",
      "$$\n",
      "\\hat{X} = S\\left(X + Z \\right)\n",
      "$$\n",
      "where $S$ is a $M$-by-$N$ random sampling matrix. Additionally, we also measure the behavior output $\\vec{y}$.\n",
      "\n",
      "The observation model's parameter is simply $M$.\n",
      "\n",
      "### Inferring $K$\n",
      "\n",
      "The inferred $K$ from the data is the number of $\\hat{X}$'s singular values above the output noise floor\n",
      "\n",
      "$$\n",
      "\\frac{\\sqrt{P} + \\sqrt{M}}{\\sqrt{N}}\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere immutable GenModel\n",
      "    N::Integer\n",
      "    K::Integer\n",
      "    P::Integer\n",
      "    r::Number\n",
      "    s::Number\n",
      "    w::Array{Float64, 1}\n",
      "    U::Array{Float64, 2}\n",
      "    \n",
      "    function GenModel(N::Integer, K::Integer, P::Integer, r::Number, s::Number)\n",
      "        U, _ = qr(randn(N, K))\n",
      "        w = U * randn(K)\n",
      "        w /= norm(w)\n",
      "        return new(N, K, P, r, s, w, U)\n",
      "    end\n",
      "end\n",
      "\n",
      "@everywhere immutable ObsModel\n",
      "    gen::GenModel\n",
      "    M::Integer\n",
      "    S::Array{Float64, 2}\n",
      "    \n",
      "    function ObsModel(gen::GenModel, M::Integer)\n",
      "        S = eye(gen.N)[randperm(gen.N)[1:M], :]\n",
      "        return new(gen, M, S)\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Sampling functions for the generative and observation models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere function rand(model::GenModel)\n",
      "    let N = model.N, K = model.K, P = model.P, r = model.r, s = model.s, w = model.w, U = model.U\n",
      "        X = U * randn(K, P) * r / sqrt(K)\n",
      "        Z = randn(N, P) / sqrt(N)\n",
      "        \u03f5 = randn(P) * s\n",
      "        y = vec(w' * (X + Z) + \u03f5')\n",
      "        \n",
      "        return {:X => X, :Z => Z, :e => \u03f5, :y => y}\n",
      "    end\n",
      "end\n",
      "\n",
      "@everywhere function rand(model::ObsModel)\n",
      "    rst = rand(model.gen)\n",
      "    rst[:Xhat] = model.S * (rst[:X] + rst[:Z])\n",
      "    return rst\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Function to find the number of signal modes, i.e. infer $K$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere function inferK(model::ObsModel, Xhat)\n",
      "    let gen = model.gen\n",
      "        _, S, _ = svd(Xhat)\n",
      "        return sum(S .> (sqrt(gen.P) + sqrt(model.M)) / sqrt(gen.N))\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Sanity Check"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, K, P, M, r, s = 1000, 5, 500, 50, 0.5, 0.0\n",
      "\n",
      "g = GenModel(N, K, P, r, s)\n",
      "o = ObsModel(g, M)\n",
      "\n",
      "rst = rand(o)\n",
      "\n",
      "S = sqrt(eigs(rst[:X] * rst[:X]'; nev=K)[1])\n",
      "signal_max, signal_min = maximum(S), minimum(S)\n",
      "println(string(\"Signal sv max, theory: \", r * (sqrt(P / K) + 1), \" numerical: \", signal_max))\n",
      "println(string(\"Signal sv min, theory: \", r * (sqrt(P / K) - 1), \" numerical: \", signal_min))\n",
      "\n",
      "S = sqrt(eigs(o.S * rst[:X] * rst[:X]' * o.S'; nev=K)[1])\n",
      "signal_max, signal_min = maximum(S), minimum(S)\n",
      "println(string(\"Sampled signal sv max, theory: \", r * (sqrt(P / K) + 1) * (sqrt(M) + sqrt(K)) / sqrt(N), \" numerical: \", signal_max))\n",
      "println(string(\"Sampled signal sv min, theory: \", r * (sqrt(P / K) - 1) * (sqrt(M) - sqrt(K)) / sqrt(N), \" numerical: \", signal_min))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### How well can we infer $w$ and decode $y$?\n",
      "\n",
      "**Problem**: given $\\hat{X}$ and $y$, find $\\hat{w}$ such that $|\\hat{w}\\hat{X} - y^T|_2$ is minimized in a validation dataset\n",
      "\n",
      "**Analysis**: what is the angle between the inferred $\\hat{w}$ and the sampled ground truth $Sw$?\n",
      "\n",
      "**Algorithm #0**: This is a cheating algorithm with $\\hat{w} = \\alpha Sw$. In other words, we simply find the best scaling of the sampled ground truth decoding vector.\n",
      "\n",
      "**Algorithm #1**: Simple linear regression of $y$ against $\\hat{X}$.\n",
      "\n",
      "**Algorithm #2**: Infer the sampled signal subspace, $\\hat{U}$, from $\\hat{X}$ first using low-rank perturbation theory, then regress $y$ against $\\hat{U}^T\\hat{X}$\n",
      "\n",
      "**Algorithm #3**: Recover the best sampled signal $\\tilde{X}$ from $\\hat{X}$ using Gavish and Donoho and the Frobenius error metric, regress $y$ against $\\tilde{X}$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# algorithm #0\n",
      "@everywhere function cheat_w(Xhat, y, model::ObsModel)\n",
      "    Sw = model.S * model.gen.w\n",
      "    alpha = sum(y .* y) / sum(y .* vec(Sw' * Xhat))\n",
      "    return alpha * Sw\n",
      "end\n",
      "\n",
      "# algorithm #1\n",
      "@everywhere function simple_w(Xhat, y)\n",
      "    return pinv(Xhat * Xhat') * (Xhat * y)\n",
      "end\n",
      "\n",
      "# algorithm #2\n",
      "@everywhere function subspace_w(Xhat, y, model::ObsModel)\n",
      "    let gen = model.gen\n",
      "        thresh = sqrt(gen.P / gen.N) + sqrt(model.M / gen.N)\n",
      "        U, S, V = svd(Xhat)\n",
      "        K = sum(S .> thresh)\n",
      "        if K < 1; return zeros(size(Xhat, 1)); end;\n",
      "        Xtilde = U[:, 1:K]' * Xhat;\n",
      "        return U[:, 1:K] * pinv(Xtilde * Xtilde') * (Xtilde * y)\n",
      "#                 return  U[:, 1:K] * ((U[:, 1:K]' * Xhat)' \\ y)\n",
      "#         return  U[:, 1:K] * ((U[:, 1:K]' * Xhat)' \\ y)\n",
      "    end\n",
      "end\n",
      "\n",
      "# algorithm #3\n",
      "@everywhere function signal_w(Xhat, y, model::ObsModel)\n",
      "    let gen = model.gen\n",
      "        U, S, V = svd(Xhat)\n",
      "        S = S * sqrt(gen.N / gen.P)\n",
      "        thresh = 1 + sqrt(model.M / gen.P)\n",
      "        beta = model.M / gen.P\n",
      "        mask = S .> thresh\n",
      "        if sum(mask) < 1; return zeros(size(Xhat, 1)); end;\n",
      "        S[mask] = sqrt(S[mask].^2 - beta - 1 + sqrt((S[mask].^2 - beta - 1).^2 - 4 * beta)) / sqrt(2)\n",
      "        S[~mask] = 0\n",
      "        Xtilde = U * diagm(S * sqrt(gen.P / gen.N)) * V'\n",
      "        return pinv(Xtilde * Xtilde') * (Xtilde * y)\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = figure(figsize=(18, 6))\n",
      "\n",
      "println(\"Left four panels shows fitted coefficients against Sw, in the order:\")\n",
      "println(\"#0,   #1\")\n",
      "println(\"#2,   #3\")\n",
      "\n",
      "@manipulate for N in [500, 2000, 5000], M in [50:50:500], K in [5:5:100], P in [50:50:1000], r in 0.0:0.2:2.0, s in 0:0.1:1\n",
      "    g = GenModel(N, K, P, r, s);\n",
      "    o = ObsModel(g, M);\n",
      "    wS = o.S * g.w\n",
      "\n",
      "    train = rand(o)\n",
      "        \n",
      "    ytest = Float64[]\n",
      "    Xtest = zeros(M, 0)\n",
      "    while length(ytest) < 10000\n",
      "        tmp = rand(o)\n",
      "        ytest = [ytest; tmp[:y]]\n",
      "        Xtest = [Xtest tmp[:Xhat]]\n",
      "    end\n",
      "        \n",
      "    what_cheat = cheat_w(train[:Xhat], train[:y], o)\n",
      "    what_simple = simple_w(train[:Xhat], train[:y])\n",
      "    what_subspace = subspace_w(train[:Xhat], train[:y], o)\n",
      "    what_signal = signal_w(train[:Xhat], train[:y], o)\n",
      "\n",
      "    angle_cheat = abs(sum(wS .* what_cheat)) / norm(wS) / norm(what_cheat)\n",
      "    angle_simple = abs(sum(wS .* what_simple)) / norm(wS) / norm(what_simple)\n",
      "    angle_subspace = abs(sum(wS .* what_subspace)) / norm(wS) / norm(what_subspace)\n",
      "    angle_signal = abs(sum(wS .* what_signal)) / norm(wS) / norm(what_signal)\n",
      "\n",
      "    err_cheat = norm(vec(what_cheat' * Xtest) - ytest)^2 / norm(ytest)^2\n",
      "    err_simple = norm(vec(what_simple' * Xtest) - ytest)^2 / norm(ytest)^2\n",
      "    err_subspace = norm(vec(what_subspace' * Xtest) - ytest)^2 / norm(ytest)^2\n",
      "    err_signal = norm(vec(what_signal' * Xtest) - ytest)^2 / norm(ytest)^2\n",
      "\n",
      "    withfig(f) do\n",
      "        subplot(261)\n",
      "        plot(wS, what_cheat, \".\")\n",
      "        title(string(\"Inferred K: \", inferK(o, train[:Xhat])))\n",
      "        subplot(262)\n",
      "        plot(wS, what_simple, \".\")\n",
      "        subplot(2, 6, 7)\n",
      "        plot(wS, what_subspace, \".\")\n",
      "        subplot(2, 6, 8)\n",
      "        plot(wS, what_signal, \".\")\n",
      "        subplot(132)\n",
      "        bar(1:4, [angle_cheat, angle_simple, angle_subspace, angle_signal])\n",
      "        xticks(1:4, [\"#0\", \"#1\", \"#2\", \"#3\"]); title(\"Overlap between Sw and w_hat\")\n",
      "        ylim([0, 1])\n",
      "        subplot(133)\n",
      "        bar(1:4, [err_cheat, err_simple, err_subspace, err_signal])\n",
      "        xticks(1:4, [\"#0\", \"#1\", \"#2\", \"#3\"]); title(\"Normalized error on held out data\");\n",
      "        ylim([1e-2, 1e2]); yscale(\"log\")\n",
      "    end    \n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Now lets explore some 2-dimensional parameters space $M$ and $P$ with fixed $K$, $N$, $r$, $s$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere overlap(v1, v2) = abs(sum(v1 .* v2)) / norm(v1) / norm(v2)\n",
      "\n",
      "@everywhere testerror(w, X, y) = norm(vec(w' * X) - y)^2 / norm(y)^2\n",
      "\n",
      "@everywhere function trial(K, N, M, P, r, s)\n",
      "    g = GenModel(N, K, P, r, s);\n",
      "    o = ObsModel(g, M);\n",
      "    wS = o.S * g.w\n",
      "\n",
      "    train = rand(o)\n",
      "        \n",
      "    ytest = Float64[]\n",
      "    Xtest = zeros(M, 0)\n",
      "    while length(ytest) < 10000\n",
      "        tmp = rand(o)\n",
      "        ytest = [ytest; tmp[:y]]\n",
      "        Xtest = [Xtest tmp[:Xhat]]\n",
      "    end\n",
      "    \n",
      "    what_cheat = cheat_w(train[:Xhat], train[:y], o)\n",
      "    what_simple = simple_w(train[:Xhat], train[:y])\n",
      "    what_subspace = subspace_w(train[:Xhat], train[:y], o)\n",
      "    what_signal = signal_w(train[:Xhat], train[:y], o)\n",
      "    \n",
      "    return map(w -> (overlap(wS, w), testerror(w, Xtest, ytest)), {what_cheat, what_simple, what_subspace, what_signal})\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere K, N, r, s = 20, 2000, 0.5, 0.1\n",
      "@everywhere Ms, Ps = 50:50:1000, 50:50:1000\n",
      "\n",
      "rst = [@spawn trial(K, N, M, P, r, s) for M = Ms, P = Ps]\n",
      "rst = map(fetch, rst)\n",
      "\n",
      "angle_cheat = map(x -> x[1][1], rst)\n",
      "angle_simple = map(x -> x[2][1], rst)\n",
      "angle_subspace = map(x -> x[3][1], rst)\n",
      "angle_signal = map(x -> x[4][1], rst)\n",
      "\n",
      "err_cheat = map(x -> x[1][2], rst)\n",
      "err_simple = map(x -> x[2][2], rst)\n",
      "err_subspace = map(x -> x[3][2], rst)\n",
      "err_signal = map(x -> x[4][2], rst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}